{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example training notebook\n",
    "#### This is an example notebook to step through the data generation and model training process. The training will be much faster with a GPU. Required packages (python3) are:\n",
    "1. Numpy, pandas, random, scikit-learn, matplotlib\n",
    "2. Tensorflow, Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import os \n",
    "import functools\n",
    "import time, timeit\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and config of tensorflow and GPU options.\n",
    "We recommend following the instructions on the Convotate git page for\n",
    "configuring the right Anaconda environment for your OS.\n",
    "Please note that tensorflow requires a GPU with cuda compute\n",
    "capability greater than 3.0, else you will need to use a CPU system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Default GPU configuration so Keras uses the GPU. \n",
    "## Comment the next line out if you do not have a GPU.\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\" \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.backend import set_session\n",
    "\n",
    "## If you are getting memory errors with the GPU, uncommenting next line might help\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "\n",
    "sess = tf.InteractiveSession()#(config=config)\n",
    "set_session(sess)\n",
    "\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape, Permute\n",
    "from keras.layers import Conv1D,MaxPool1D #Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import Conv2D, Dense, MaxPool2D, Flatten\n",
    "from keras.layers import LeakyReLU, Dropout, PReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.engine.topology import Layer\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def time_it(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        t = time.time()\n",
    "        f = func(*args, **kwargs)\n",
    "        print('%s , dt = %.2g s' %(func.__name__,time.time()-t))\n",
    "        return f\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class TimeHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "\n",
    "class EpochHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "        self.best_weights = None\n",
    "        self.best_val_acc = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        print('Ep: %d\\tAcc: %.4f\\tVal. Acc: %.4f' % (epoch, self.acc[-1], self.val_acc[-1]))\n",
    "        if self.val_acc[-1] > self.best_val_acc:\n",
    "            self.best_val_acc = self.val_acc[-1]\n",
    "            print('Val Acc improved; getting weights')\n",
    "            self.best_weights = self.model.get_weights()\n",
    "            print('saving model')\n",
    "            self.model.save('superclass_test_deep_model_fig_20190516_SPP32.h5')  # %(self.model.__model_name__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Pyramidal Pooling\n",
    "We have modified this code for our 1D data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SpatialPyramidPooling1D(Layer):\n",
    "    \"\"\"Spatial pyramid pooling layer for 2D inputs.\n",
    "    See Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition,\n",
    "    K. He, X. Zhang, S. Ren, J. Sun\n",
    "    # Arguments\n",
    "        pool_list: list of int\n",
    "            List of pooling regions to use. The length of the list is the number of pooling regions,\n",
    "            each int in the list is the number of regions in that pool. For example [1,2,4] would be 3\n",
    "            regions with 1, 2x2 and 4x4 max pools, so 21 outputs per feature map\n",
    "    # Input shape\n",
    "        3D tensor with shape:\n",
    "        `(samples, rows, channels)` if dim_ordering='tf'.\n",
    "    # Output shape\n",
    "        2D tensor with shape:\n",
    "        `(samples, channels * sum([i * i for i in pool_list])`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pool_list, **kwargs):\n",
    "\n",
    "        self.dim_ordering = K.image_dim_ordering()\n",
    "        assert self.dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'\n",
    "        self.pool_list = pool_list\n",
    "        self.num_outputs_per_channel = sum([i for i in pool_list])\n",
    "\n",
    "        super(SpatialPyramidPooling1D, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.dim_ordering == 'th':\n",
    "            self.nb_channels = input_shape[1]\n",
    "        elif self.dim_ordering == 'tf':\n",
    "            self.nb_channels = input_shape[-1]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.nb_channels * self.num_outputs_per_channel)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'pool_list': self.pool_list}\n",
    "        base_config = super(SpatialPyramidPooling1D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        input_shape = K.shape(x)\n",
    "        if self.dim_ordering == 'th':\n",
    "            num_rows = input_shape[2]\n",
    "        elif self.dim_ordering == 'tf':\n",
    "            num_rows = input_shape[1]\n",
    "        row_length = [K.cast(num_rows, 'float32') / i for i in self.pool_list]\n",
    "\n",
    "        outputs = []\n",
    "        if self.dim_ordering == 'tf':\n",
    "            for pool_num, num_pool_regions in enumerate(self.pool_list):\n",
    "                for jy in range(num_pool_regions):\n",
    "                        y1 = jy * row_length[pool_num]\n",
    "                        y2 = jy * row_length[pool_num] + row_length[pool_num]\n",
    "                        y1 = K.cast(K.round(y1), 'int32')\n",
    "                        y2 = K.cast(K.round(y2), 'int32')\n",
    "                        new_shape = [input_shape[0], y2 - y1,\n",
    "                                     input_shape[-1]]\n",
    "                        x_crop = x[:, y1:y2, :]\n",
    "                        xm = K.reshape(x_crop, new_shape)\n",
    "                        pooled_val = K.max(xm, axis=(1,))\n",
    "                        outputs.append(pooled_val)\n",
    "        \n",
    "        else:\n",
    "            raise TypeError()\n",
    "\n",
    "        if self.dim_ordering == 'th':\n",
    "            outputs = K.concatenate(outputs)\n",
    "        elif self.dim_ordering == 'tf':\n",
    "            outputs = K.concatenate(outputs)\n",
    " \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DMN_Conv:\n",
    "    def __init__(self,input_tensor, kernel_size = (3,3), strides=(1,1), var_explained = 0.99, **kw):\n",
    "        self.kernel_size = list(kernel_size)\n",
    "        self.strides = list(strides)\n",
    "        self.input_tensor = input_tensor\n",
    "        self.get_patches()\n",
    "        self.get_rho()\n",
    "        self.get_eigs()\n",
    "        self.get_num_filters(var_explained)\n",
    "        self.make_weights()\n",
    "    \n",
    "    @time_it\n",
    "    def get_patches(self):\n",
    "        self.patches = tf.image.extract_image_patches( self.input_tensor, \n",
    "                ksizes = [1]+list(self.kernel_size)+[1],\n",
    "                strides = [1]+list(self.strides)+[1],\n",
    "                rates = [1,1,1,1], padding = 'VALID')    \n",
    "    \n",
    "    @time_it    \n",
    "    def get_rho(self):\n",
    "        \"\"\"To be able to update the eigenvectors later, we will keep the covariance matrix, instead of doing SVD directly. \n",
    "        In most cases since # of samples N >> dim this won't be much more costly than SVD\"\"\"\n",
    "        ims = tf.reshape(self.patches, [-1, self.patches.shape.as_list()[-1]])\n",
    "        self.rho = tf.matmul(ims, ims, transpose_a=True)\n",
    "    \n",
    "    @time_it\n",
    "    def get_eigs(self):\n",
    "        \"\"\"svd automatically finds SVs from largest to smallest, so no sorting is needed for PCA.\"\"\"\n",
    "        self.eigs = tf.svd(self.rho)\n",
    "    \n",
    "    @time_it    \n",
    "    def get_num_filters(self, v):\n",
    "#         ei = self.eigs[0].eval()\n",
    "#         ex = (ei / ei.sum()).cumsum()\n",
    "#         self.num_filters = (ex < v).sum()\n",
    "        c = tf.cumsum(self.eigs[0] )\n",
    "        c = c/ c[-1]\n",
    "        self.num_filters = tf.reduce_sum(tf.cast(c < v, dtype=tf.int32))\n",
    "\n",
    "    @time_it\n",
    "    def make_weights(self):\n",
    "        self.weights = tf.reshape(self.eigs[1], list(self.kernel_size) + [self.input_tensor.shape.as_list()[-1],-1,] )[..., :self.num_filters]\n",
    "\n",
    "\n",
    "def plot_ws(ws, idx='all'):\n",
    "    figure(figsize=(12,12))\n",
    "    n = ws.shape[-1]\n",
    "    r = np.ceil(np.sqrt(n))\n",
    "    for i in range(n):\n",
    "        subplot(r,r,i+1)\n",
    "        w = (ws[...,i] if idx == 'all' else ws[...,idx,i]) # ws.shape[-2]==3\n",
    "        imshow(w +.5, interpolation='bicubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DMN_Class_Data:\n",
    "    def __init__(self, x,y):\n",
    "        self.x, self.y = self.prep_input(x), np.asarray(y)\n",
    "        self.get_class_indices()\n",
    "        self.get_all_class_tensors()\n",
    "    \n",
    "    @time_it\n",
    "    def prep_input(self, x):\n",
    "        x = np.asarray((x if len(x.shape)==4 else x[...,newaxis]))\n",
    "        return (x-x[:2].min()) / x[:2].max() - 0.5\n",
    "    \n",
    "    @time_it\n",
    "    def get_all_class_tensors(self):\n",
    "        self.class_tensors = {c: tf.constant(self.x[self.classes[c]], tf.float32) for c in self.classes} \n",
    "        \n",
    "    @time_it\n",
    "    def get_class_indices(self):\n",
    "        self.classes = set(self.y.flatten())\n",
    "        self.classes = {}\n",
    "        for i, c in enumerate(self.y.flatten()):\n",
    "            self.classes.setdefault(c,[])\n",
    "            self.classes[c] += [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DMN_Layer:\n",
    "    def __init__(self, x,y, frac = 0.5, **kwargs):\n",
    "        self._n = int(frac*len(x))\n",
    "        self.Training_Data = DMN_Class_Data(x[:self._n],y[:self._n])\n",
    "        self.get_class_weights(**kwargs)\n",
    "        \n",
    "    @time_it\n",
    "    def get_class_weights(self, **kw):\n",
    "        self.class_weights = {}\n",
    "        for c, ten in self.Training_Data.class_tensors.items():\n",
    "            self.class_weights[c] = DMN_Conv(ten, **kw)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_model_name(model):\n",
    "    mn = []\n",
    "    for l in model.layers:\n",
    "        nam = l.name\n",
    "        if 'conv' in nam:\n",
    "            s = 'Conv1D(%d,%d)'%((l.filters,)+l.kernel_size)  \n",
    "        elif 'max_pool' in nam:\n",
    "            s = 'MaxPool%d'%l.pool_size\n",
    "        elif 'dense' in nam:\n",
    "            s = 'Dense%d'%l.units\n",
    "        elif 'dropout' in nam:\n",
    "            s = 'Dropout%.1g'%l.rate\n",
    "        else:\n",
    "            continue\n",
    "        mn += [s]\n",
    "    return '-'.join(mn)\n",
    "\n",
    "class EpochHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "        self.best_weights = None\n",
    "        self.best_val_acc = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        print('Ep: %d\\tAcc: %.4f\\tVal. Acc: %.4f' %(epoch, self.acc[-1], self.val_acc[-1]) )\n",
    "        if self.val_acc[-1] > self.best_val_acc:\n",
    "            self.best_val_acc = self.val_acc[-1]\n",
    "            print('Val Acc improved; getting weights')\n",
    "            self.best_weights = self.model.get_weights()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Train_Proteins:\n",
    "    def __init__(self,sequence_file = './data/training_validation/training_sequences.txt' ,\n",
    "                labels_file = './data/training_validation/labels.txt',\n",
    "                ontology_file = './data/training_validation/ontology_merged.txt'):\n",
    "        self.get_ontology(ontology_file)\n",
    "        print('Loading protein sequences...')\n",
    "        self.proteins = pd.read_csv(sequence_file, sep = '\\t')\n",
    "        print('Loading protein class data...')\n",
    "        self.patric = pd.read_csv(labels_file, sep = '\\t')\n",
    "        # Unfortunately, to compare patric and prot seq data we need to load both files into RAM... \n",
    "        \n",
    "        self.prep_seqs()\n",
    "        self.get_amino_acids()\n",
    "        self.set_seq_lengths()\n",
    "        self.compile_class_data(chosen_level)\n",
    "        \n",
    "    def get_ontology(self, ont_file):\n",
    "        \"\"\"mapping 'Subsystem' to other levels ('Superclass', 'Class', 'Subclass') \"\"\"\n",
    "        ont = pd.read_csv(ont_file, sep = '\\t')\n",
    "        self.ontology = {ont['Subsystem Merged'][i]: {k: str(ont[k][i]).strip() for k in ['Superclass', 'Class', 'Subclass']} \n",
    "                         for i in range(len(ont))}\n",
    "        \n",
    "        \n",
    "    @time_it    \n",
    "    def prep_seqs(self):\n",
    "        # index all gene patric ids\n",
    "        # ignore duplicates, we checked, the sequences are unique \n",
    "        print('preparing sequences...')\n",
    "        self.pid2index = {k:i for i, k in enumerate(self.patric['PATRIC ID'].values)}        \n",
    "        self.pseq_shared = {k:seq for k, seq in self.proteins.values if k in self.pid2index}\n",
    "\n",
    "    @time_it    \n",
    "    def get_amino_acids(self):\n",
    "        print('getting amino acid list...')\n",
    "        import string\n",
    "        self.amino_acids = {a:i for i,a in enumerate(string.ascii_uppercase+'_')} # '_':unknown stuff\n",
    "        print(self.amino_acids)\n",
    "\n",
    "    @time_it    \n",
    "    def set_seq_lengths(self, sigma = 3, viz=True):\n",
    "        print('calculating length truncation for sequences', end=', ' )\n",
    "        seq_lens = np.array([len(self.pseq_shared[k]) for k in self.pseq_shared])\n",
    "        self.min_seq_length = int(np.exp(np.log(seq_lens).mean()-sigma*np.log(seq_lens).std()))\n",
    "        self.max_seq_length = int(np.exp(np.log(seq_lens).mean()+sigma*np.log(seq_lens).std()))\n",
    "        print('Length = %d' %self.max_seq_length)\n",
    "        if viz:\n",
    "            h= plt.hist(np.log10(seq_lens), 100, log = 1)\n",
    "            plt.xlabel('log sequence length')\n",
    "            plt.ylabel('count')\n",
    "            plt.show()\n",
    "\n",
    "    def make_barcode(self, seq):\n",
    "        protein_barcodes = np.zeros((1950, len(self.amino_acids)), dtype = np.float16)\n",
    "        s = np.sqrt(len(self.amino_acids))\n",
    "        for i2,j in enumerate(seq[:1950]):\n",
    "            protein_barcodes[i2,self.amino_acids[j]] = 1/s\n",
    "        return protein_barcodes\n",
    "    \n",
    "    @time_it\n",
    "    def compile_class_data(self, class_level = 3, min_len ='auto'):\n",
    "        \"\"\"class_level:\n",
    "            0: Superclass, 1: Class, 2: Subclass, 3: Subsystem Name\n",
    "        min_len: minimum length of sequence to include.      \n",
    "        \"\"\"\n",
    "        min_len = (self.min_seq_length if min_len == 'auto' else min_len)\n",
    "        label = lambda i: '>'.join([str(j).strip() for j in i]) \n",
    "        \n",
    "        self.class_level = ['Superclass', 'Class', 'Subclass','Subsystem Merged'][:class_level+1]\n",
    "        \n",
    "        # instead of directly joining all levels, we will use the ontology\n",
    "        labs = []\n",
    "        missing = set()\n",
    "        for i in self.patric[['Superclass', 'Class', 'Subclass','Subsystem Merged']].values:\n",
    "            try:\n",
    "                sub_sys = self.ontology[i[-1]]\n",
    "                lab = label([sub_sys[k] for k in self.class_level[:3]])\n",
    "                if class_level == 3:\n",
    "                    lab += '>'+str(i[-1]).strip()\n",
    "                \n",
    "                labs += [lab]\n",
    "            except KeyError:\n",
    "                t = tuple(i)\n",
    "                if t not in missing:\n",
    "                    print(t)\n",
    "                    missing.add(t)\n",
    "        \n",
    "        s = set(labs)\n",
    "        \n",
    "        print(\"Compiling label information; level: %s\" %(self.class_level[class_level]))\n",
    "        self.patric_class_names_to_index = {k:i for i,k in enumerate(sorted(s))}\n",
    "        self.patric_id_to_class = {p:s for s,p in zip(labs, self.patric['PATRIC ID'].values) }\n",
    "        self.class_gene_list = {k:[] for k in self.patric_class_names_to_index}\n",
    "        for p in self.pseq_shared: \n",
    "            if len(self.pseq_shared[p]) < min_len: continue\n",
    "            try:\n",
    "                self.class_gene_list[self.patric_id_to_class[p]] += [p]\n",
    "            except KeyError:\n",
    "                continue\n",
    "        self.class_sizes = {k:len(v) for k,v in self.class_gene_list.items()}\n",
    "        # to create training batches, we should keep consistent indices\n",
    "        self.rand_indices = {k: np.argsort(np.random.rand(self.class_sizes[k])) for k in self.class_sizes}\n",
    "        self.batch_num = 0\n",
    " \n",
    "    @time_it\n",
    "    def make_training_data(self, batch_size = 120000):\n",
    "        y_train = []\n",
    "        self.X_train = []\n",
    "        self.X_train_ids = []\n",
    "\n",
    "        m = batch_size / len(self.class_gene_list)\n",
    "\n",
    "        for k in self.class_gene_list:\n",
    "            # choose at most m genes randomly\n",
    "            numGenesToSelect=min(int(m), len(self.class_gene_list[k]))\n",
    "            numGenesInCategory=len(self.class_gene_list[k])\n",
    "            \n",
    "            geneIndices=random.sample(range(0, numGenesInCategory), numGenesToSelect)\n",
    "            \n",
    "            for i in geneIndices:\n",
    "                g = self.class_gene_list[k][i]\n",
    "                self.X_train_ids += [g]\n",
    "                y_train += [self.patric_class_names_to_index[self.patric_id_to_class[g]]]\n",
    "                self.X_train += [self.make_barcode(self.pseq_shared[g]) ] \n",
    "\n",
    "        idx1 = np.argsort(np.random.rand(len(y_train))) \n",
    "        self.geneIndices = geneIndices\n",
    "        self.IDX1 = idx1\n",
    "        self.X_train = np.array(self.X_train)[idx1]\n",
    "        self.X_train_ids = np.array(self.X_train_ids)[idx1]\n",
    "        \n",
    "        self.Y_train = tf.keras.utils.to_categorical(y_train, num_classes=len(self.patric_class_names_to_index))[idx1]\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training data\n",
    "Training and validation data are housed in separate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading protein sequences...\n",
      "Loading protein class data...\n",
      "preparing sequences...\n",
      "prep_seqs , dt = 0.019 s\n",
      "getting amino acid list...\n",
      "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25, '_': 26}\n",
      "get_amino_acids , dt = 4.7e-05 s\n",
      "calculating length truncation for sequences, Length = 2107\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 261,
       "width": 387
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_seq_lengths , dt = 0.57 s\n",
      "Compiling label information; level: Subsystem Merged\n",
      "compile_class_data , dt = 0.057 s\n",
      "Loading protein sequences...\n",
      "Loading protein class data...\n",
      "preparing sequences...\n",
      "prep_seqs , dt = 0.0056 s\n",
      "getting amino acid list...\n",
      "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25, '_': 26}\n",
      "get_amino_acids , dt = 0.00036 s\n",
      "calculating length truncation for sequences, Length = 1963\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 261,
       "width": 387
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_seq_lengths , dt = 0.57 s\n",
      "Compiling label information; level: Subsystem Merged\n",
      "compile_class_data , dt = 0.051 s\n"
     ]
    }
   ],
   "source": [
    "## Assign files\n",
    "training_sequence_file = './data/training_validation/training_sequences.txt'\n",
    "validation_sequence_file = './data/training_validation/test_sequences.txt'\n",
    "labels_file = './data/training_validation/labels.txt'\n",
    "\n",
    "# training_sequence_file = '/home/fish0208/amazons3/protclass/patricdata/training/FinalDataFiles/train_aaseq_fig_only_over30aa.txt'\n",
    "# validation_sequence_file = '/home/fish0208/amazons3/protclass/patricdata/training/FinalDataFiles/validation_aaseq_fig_only_over30aa.txt'\n",
    "# labels_file = '/home/fish0208/amazons3/protclass/patricdata/training/FinalDataFiles/ssid_universal_190612_lowfreq_andAA_cut.txt'\n",
    "\n",
    "## Choose level. 0 = Superclass, 1 = Class, 2 = Subclass, 3 = Subsystem\n",
    "chosen_level = 3\n",
    "\n",
    "## Create data for training and testing\n",
    "training = Train_Proteins(sequence_file=training_sequence_file, labels_file=labels_file)\n",
    "validation = Train_Proteins(sequence_file=validation_sequence_file, labels_file=labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_training_data , dt = 3.5 s\n",
      "make_training_data , dt = 0.52 s\n"
     ]
    }
   ],
   "source": [
    "## Make training and validation data. \n",
    "## Note: dataset creation is nonlinear in memory. More than 40,000 sequences can start to get RAM heavy.\n",
    "## Set different minimum sequence length if desired (current is 30).\n",
    "\n",
    "# training.compile_class_data(min_len=30)\n",
    "# validation.compile_class_data(min_len=30)\n",
    "\n",
    "number_training_sequences = 12560\n",
    "number_validation_sequences = 2512\n",
    "\n",
    "training.make_training_data(number_training_sequences)\n",
    "validation.make_training_data(number_validation_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise a barcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "index = 10 # change index to see a different protein if it's boring\n",
    "\n",
    "H=training.X_train[index]\n",
    "H=H.astype(float64)\n",
    "H=H.transpose()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(H,aspect=10)\n",
    "plt.figure(figsize=(10,5))\n",
    "ax.set_ylabel('AA label')\n",
    "ax.set_xlabel('AA position')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Parameters\n",
    "num_filters = 2 ** 9\n",
    "pool_list = [1, 4, 16, 32]  # Spatial pyramidal pooling layers\n",
    "\n",
    "ps = 2\n",
    "kernel_size = 100\n",
    "ep_hist2 = EpochHistory()\n",
    "pool = max(2, int(kernel_size / ps))  \n",
    "\n",
    "## Keras Sequential model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(num_filters, kernel_size=kernel_size, activation='relu', \n",
    "                  input_shape=validation.X_train[0].shape))\n",
    "model.add(SpatialPyramidPooling1D(pool_list))  # , dim_ordering='tf'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(validation.Y_train.shape[-1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "## Initiate model\n",
    "sc_len = np.array([[k, len(v)] for k, v in training.class_gene_list.items()])\n",
    "l = np.int0(sc_len[:, 1]).sum()\n",
    "\n",
    "## Weights can either be loaded from a pretrained model or set to a weighted average if you want to start from scratch \n",
    "## uncomment next two lines to train from scratch\n",
    "\n",
    "# sc_len = np.array([[k,len(v)] for k,v in validation.class_gene_list.items()])\n",
    "## weights = {training.patric_class_names_to_index[c]: l / (int(n)+1) for c, n in sc_len}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "## Selects weights to load based on your chosen class level\n",
    "\n",
    "shallow_model_files = ['models/superclass.h5', 'models/class.h5', 'models/subclass.h5', 'models/subsystem.h5']\n",
    "\n",
    "model.load_weights(shallow_model_files[chosen_level])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "Uncomment section below to train (if the dataset you use is small, you might decrease the accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "acc2 = [] \n",
    "val_acc2 = []\n",
    "\n",
    "# try:\n",
    "#     acc2 += ep_hist2.acc\n",
    "#     val_acc2 += ep_hist2.val_acc\n",
    "# except AttributeError:\n",
    "#     pass\n",
    "# time_callback = TimeHistory()\n",
    "# model.fit(training.X_train, training.Y_train, \n",
    "#                validation_data=(validation.X_train, validation.Y_train), \n",
    "#                epochs=12, callbacks=[ep_hist2], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions and results\n",
    "#### Get model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Get index information\n",
    "sc_len = np.array([[k, len(v)] for k, v in validation.class_gene_list.items()])\n",
    "l = np.int0(sc_len[:, 1]).sum()\n",
    "\n",
    "## Run predictions\n",
    "start_time = timeit.default_timer()\n",
    "pred = model.predict(validation.X_train[-l:])  \n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print('Time elapsed for predictions was',elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assess the (complete) results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "true_classes=validation.Y_train[-l:].argmax(axis=-1)\n",
    "pred_classes = pred.argmax(axis=-1)\n",
    "\n",
    "## Create the confusion matrix and classification report \n",
    "C=confusion_matrix(true_classes, pred_classes)\n",
    "target_names = pd.DataFrame(validation.patric_class_names_to_index, index=[0]).columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Look at the f1-score and classification report\n",
    "f1=f1_score(true_classes, pred_classes, average='weighted')\n",
    "predictions_report=classification_report(true_classes, pred_classes,digits=4)\n",
    "\n",
    "print('The f1-score is',f1)\n",
    "# print(predictions_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get high confidence predictions only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Choose a confidence threshhold\n",
    "conf_threshhold = 0.99\n",
    "\n",
    "\n",
    "## extract the data\n",
    "pred_rank = argsort(pred)\n",
    "confidence = array([p[i] for p,i in zip(pred, pred_rank[:,-1])])\n",
    "idx = where(confidence > conf_threshhold)\n",
    "\n",
    "\n",
    "true_classes_highconf=validation.Y_train[-l:][idx].argmax(axis=-1)\n",
    "pred_classes_highconf = pred[idx].argmax(axis=-1)\n",
    "\n",
    "\n",
    "print('Confidence %.2f \\n Fraction of data covered %.3f' % (conf_threshhold, len(idx[0])/len(confidence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Get confusion matrix, classification report, and f1-score\n",
    "## Note that with small sample sizes, a high confidence threshhold may result in some classes having no sequences in them. In this case, Scikit-learn will show a warning.\n",
    "\n",
    "high_conf_confusion = confusion_matrix(true_classes_highconf, pred_classes_highconf)\n",
    "target_names = pd.DataFrame(validation.patric_class_names_to_index, index=[0]).columns.values\n",
    "\n",
    "high_conf_classification_report = classification_report(true_classes_highconf, pred_classes_highconf, digits=4)\n",
    "high_conf_f1 = f1_score(true_classes[idx], pred_classes[idx], average='weighted')\n",
    "\n",
    "print('High confidence f1-score is',high_conf_f1)\n",
    "# print(high_conf_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Architecture\n",
    "This is the code for the deep architecture. You can run the next two cells and then go back to the predictions section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "## Choose model file based on your chosen level\n",
    "\n",
    "deep_model_files = ['models/deep_superclass.h5', 'models/deep_class.h5', 'models/deep_subclass.h5', 'models/deep_subsystem.h5']\n",
    "\n",
    "deep_model_weights = deep_model_files[chosen_level]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We want two convolutional layers with 25 and 200 filters. First try one \n",
    "nf = 2**7\n",
    "# kernel_size = 100 #25\n",
    "# pool = int(kernel_size /3) # int(kernel_size/2)\n",
    "\n",
    "ps = 2\n",
    "# for ps in range(2,5):\n",
    "kernel_size = 100\n",
    "ep_hist = EpochHistory()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(nf, kernel_size = 6, input_shape = training.X_train[0].shape))\n",
    "model.add((PReLU()))\n",
    "model.add(BatchNormalization(scale=False))\n",
    "\n",
    "model.add(Conv1D(nf, kernel_size = 6))\n",
    "model.add((PReLU()))\n",
    "model.add(BatchNormalization(scale=False))\n",
    "model.add(MaxPool1D(pool_size=2, strides=2 ))\n",
    "\n",
    "model.add(Conv1D(nf*2, kernel_size = 5))\n",
    "model.add((PReLU()))\n",
    "model.add(BatchNormalization(scale=False))\n",
    "model.add(MaxPool1D(pool_size=2, strides=2 ))\n",
    "\n",
    "model.add(Conv1D(nf*2, kernel_size = 5))\n",
    "model.add((PReLU()))\n",
    "model.add(BatchNormalization(scale=False))\n",
    "model.add(MaxPool1D(pool_size=2, strides=2 ))\n",
    "\n",
    "model.add(Conv1D(nf*4, kernel_size = 5))\n",
    "model.add((PReLU()))\n",
    "model.add(BatchNormalization(scale=False))\n",
    "model.add(MaxPool1D(pool_size=2, strides=2 ))\n",
    "\n",
    "model.add(Conv1D(nf*4, kernel_size = 5))\n",
    "model.add((PReLU()))\n",
    "model.add(BatchNormalization(scale=False))\n",
    "model.add(MaxPool1D(pool_size=2, strides=2 ))\n",
    "\n",
    "# model.add(Permute((2,1)))\n",
    "# model.add(Reshape((512,1,52)))\n",
    "model.add(SpatialPyramidPooling1D([1,4,16])) #, dim_ordering='tf'))\n",
    "\n",
    "# model.add(Flatten())\n",
    "model.add(Dense(nf*8))\n",
    "model.add((PReLU()))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(BatchNormalization(scale=True))\n",
    "model.add(Dense(training.Y_train.shape[-1], activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.load_weights(deep_model_weights)\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
